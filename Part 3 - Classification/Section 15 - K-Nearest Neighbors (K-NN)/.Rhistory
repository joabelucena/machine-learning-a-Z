q()
getwd()
setwd("C:/Users/Joabe/Dropbox/ACADEMICO/FIA/05 - Machine Learning/180302_Machine Learning (Carlos Relvas)")
x=3
y<-5
x+y
x = c(1,2,3, 7)
y= c(2,3,5,1)
x+y
x*y
x-y
x/y
length(x)
x = 1:10
x
summary(x)
mean(a = c(1,2,3))
y = 1:9
# warning mas volta soma no início
x+y
x[1:3]
1:3
x = c(1,2,3,4,5,6,7,8,9,10)
x[1:3]
x[c(1,3,5)] * 2 + x[c(2,2,2)]
x[c(1,3,5)] * 2
x[c(2,2,2)]
x[c(2,2,2)]
x[c(1,3,5)] * 2 + x[c(2,2,2)]
x[-(1:6)]
e <- list(thing="hat", size=8.25)
e
e$size
e$siaze
df = data.frame(a=c(1,2,3,4,5),b=c(2,3,4,5,6))
View(df)
View(df)
df
df$a
for(i in 1:100){
x <- x+i
}
x
df[,1]
df$a
#ou todas as linhas primeira coluna
df[,1]
df$a[df$a>3,]
df$a
df$a[df$a>3,]
m = rbind(c(1,2,3),c(4,5,6))
m
dim(m)
m = cbind(c(1,2,3),c(4,5,6))
m
m1<-matrix(c(1,2,3,4),nrow=2)
m1
m2<-matrix(c(5,6),nrow=2)
m2
m1*m2
m1%*%m2
solve(matrix(c(1,2,3,4),nr=2))
t(matrix(c(1,2,3,4),nr=2))
solve(matrix(c(1,2,3,4),nr=2))
f <- function(x) {
return(x^2 + 3)
}
f(4)
f <- function(x, y) {
return(list(x^2 + 3, y^2))
}
f(4)
f(4, 5)
x <- 1
if (x==1){
print("X é igual a 1")
}
x <- 0
for(i in 1:100){
x <- x+i
}
x
ifelse(round(x/2,0), T,F)
ifelse(round(x/2,0)==0, T,F)
ifelse(x%2, T,F)
ifelse(x%/%2, T,F)
x <- 1:1000
ifelse(x%/%2, T,F)
ifelse(x%/%2==0, T,F)
ifelse(x%/%2==0, T,F)
x <- 1:1000
x
ifelse(x%/%2==0, T,F)
ifelse(x%%2==0, T,F)
x<-matrix(0, nrow = 10, nc = 10)
apply(x, c(1,2), function (x) x%%2==0)
x <- 0
for(i in 1:100){
x <- x+i
}
x
sum(1:100)
x <- rnorm(100)
y <- x*3 + rnorm(100,0, 2.8)
par(mfrow = c(1,2))
plot(x, y, pch=16, main="Gráfico de Dispersão X vs Y",
xlab="Variável X", ylab="Variável Y")
hist(x, main="Histograma de X",
xlab="Variável X", ylab="Frquência")
hist(x, main="Histograma de X",
xlab="Variável X", ylab="Frquência", col="blue")
plot(x, y, pch=16, main="Gráfico de Dispersão X vs Y",
xlab="Variável X", ylab="Variável Y", pch=32)
plot(x, y, pch=16, main="Gráfico de Dispersão X vs Y",
xlab="Variável X", ylab="Variável Y")
plot(x, y, pch=16, main="Gráfico de Dispersão X vs Y",
xlab="Variável X", ylab="Variável Y")
plot(x, y, pch=34, main="Gráfico de Dispersão X vs Y",
xlab="Variável X", ylab="Variável Y")
setwd("C:/Users/Joabe/Dropbox/ACADEMICO/UDEMY/Machine Learning A-Z/Part 3 - Classification/Section 14 - Logistic Regression")
#Logistic Regression
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[,3:5]
# Splitting the dataset into the Training set and Test set
# # install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2] = scale(test_set[,1:2])
# Fitting the Classification Model to the dataset
classifier = glm(formula = Purchased ~ .,
family = binomial,
data = training_set)
# Predicting the Test set results
# type = 'response' beacause give the probability in a single vector
# tesst_set[-3] remove the last column because is the response column
prob_pred = predict(classifier, type = 'response', newdata = test_set[-3])
y_pred = ifelse(prob_pred > 0.5, 1, 0)
# Making the Confusion Matrix
cm = table(test_set[,3], y_pred)
# Visualising the Classification Model results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
plot(set[, -3],
main = 'Logistic Regression (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
setwd("C:/Users/Joabe/Dropbox/ACADEMICO/FIA/05 - Machine Learning/180302_Machine Learning (Carlos Relvas)")
dados <- read.table("base_gastos_cartao.csv", sep=",", header=T)
head(dados)
summary(dados)
dados <- read.table("base_gastos_cartao.csv", sep=",", header=T)
head(dados)
summary(dados)
table(dados$Segmento)
quantile(dados$Gastos_Cartao,
probs = c(0.01, 0.05, 0.1, 0.9, 0.95, 0.99))
View(dados)
View(dados)
table(dados$Ida)
quantile(dados$Idade,
probs = c(0.01, 0.05, 0.1, 0.9, 0.95, 0.99))
quantile(dados$Renda,
probs = c(0.01, 0.05, 0.1, 0.9, 0.95, 0.99))
quantile(dados$Impostos,
probs = c(0.01, 0.05, 0.1, 0.9, 0.95, 0.99))
vars <- names(dados)[1:4]
for(i in vars){
par(mfrow=c(2,1))
hist(dados[,i], breaks = 20, main=paste0("Histograma - ", i),
xlab=i, ylab="Frequ?ncia", col="dark blue")
boxplot(dados[,i], main=paste0("Boxplot - ", i),
ylab=i, col="dark red")
}
"asdas" + "kkkkkkkkk"
"asdas" % "kkkkkkkkk"
"asdas" & "kkkkkkkkk"
"asdas" %+% "kkkkkkkkk"
vars <- names(dados)
for(i in vars){
cat(paste0(i, " - n?mero de observa??es missing: ",
sum(is.na(dados[,i]))),"\n")
}
vars <- names(dados)
for(i in vars){
cat(paste0(i, " - n?mero de observa??es missing: ",
sum(is.na(dados[,i]))),"\n")
}
vars <- names(dados)[1:4]
cor(dados[,vars])
library(car)
install.packages("car")
library(car)
scatterplotMatrix(~ Gastos_Cartao + Idade + Renda +
Impostos, data=dados, smooth=FALSE,
reg.line=FALSE, ellipse=FALSE,
diagonal="none", pch=16)
scatterplotMatrix(~ Gastos_Cartao + Idade + Renda +
Impostos, data=dados, smooth=FALSE,
reg.line=FALSE, ellipse=FALSE,
groups=as.factor(dados$Segmento), diagonal="none")
plot(dados$Idade, dados$Gastos_Cartao, pch=16, main="Gr?fico de dispers?o",
xlab = "Idade", ylab="Gastos Cart?o", ylim=c(200,1000))
scatterplotMatrix(~ Gastos_Cartao + Idade + Renda +
Impostos, data=dados, smooth=FALSE,
reg.line=FALSE, ellipse=FALSE,
by.groups=TRUE, diagonal="none")
scatterplotMatrix(~ Gastos_Cartao + Idade + Renda +
Impostos | Segmento, data=dados, smooth=FALSE,
reg.line=FALSE, ellipse=FALSE,
by.groups=TRUE, diagonal="none")
View(dados)
plot(dados$Idade, dados$Gastos_Cartao, pch=16, main="Gr?fico de dispers?o",
xlab = "Idade", ylab="Gastos Cart?o", ylim=c(200,1000))
for(i in names(dados)[1:4]){
boxplot(dados[,i] ~ as.factor(dados$Segmento), main=paste0("Boxplot - ",i),
xlab="Segmento", ylab=i, col="dark red")
}
par(mfrow=c(1,1))
boxplot(dados[,i] ~ as.factor(dados$Segmento), main=paste0("Boxplot - ",i),
xlab="Segmento", ylab=i, col="dark red")
dados <- read.table("base_gastos_cartao.csv", sep=",", header=T)
nrow(dados)
set.seed(432)
id <- sample(1:nrow(dados), nrow(dados)*0.7)
dados.des <- dados[id,]
dados.test <- dados[-id,]
View(dados.des)
View(dados.test)
id <- sample(1:nrow(dados), nrow(dados)*0.7)
fit <- lm(Gastos_Cartao~Renda, data = dados.des)
summary(fit)
summary(fit)
set.seed(42)
id <- sample(1:nrow(dados), nrow(dados)*0.7)
dados.des <- dados[id,]
dados.test <- dados[-id,]
fit <- lm(Gastos_Cartao~Renda, data = dados.des)
summary(fit)
fit.val <- predict(fit, newdata=dados.test)
head(fit.val)
setwd("C:/Users/Joabe/Dropbox/ACADEMICO/UDEMY/Machine Learning A-Z/Part 3 - Classification/Section 15 - K-Nearest Neighbors (K-NN)")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
install.packages('class')
library(class)
y_pred = knn(train = training_set[, -3],
test = test_set[-3],
cl = training_set[, 3],
k = 5)
y_p
y_pred
cm = table(test_set[, 3], y_pred)
cm
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3],
main = 'KNN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = knn(train = training_set[, -3],
test = grid_set,
cl = training_set[, 3],
k = 5)
plot(set[, -3],
main = 'KNN (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
# Updated from template
y_grid = knn(train = training_set[, -3],
test = grid_set,
cl = training_set[, 3],
k = 5)
plot(set[, -3], main = 'KNN (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
